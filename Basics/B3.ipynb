{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr = pd.read_csv('https://raw.githubusercontent.com/skathirmani/datasets/master/HR%20Analytics.csv')\n",
    "hr_dummies = pd.get_dummies(hr)\n",
    "\n",
    "\n",
    "train, test = train_test_split(hr_dummies,\n",
    "                               test_size=0.3,\n",
    "                               random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=300, random_state=100)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = train.drop('Attrition', axis=1)\n",
    "train_y = train['Attrition']\n",
    "\n",
    "test_x = test.drop('Attrition', axis=1)\n",
    "test_y = test['Attrition']\n",
    "\n",
    "model = AdaBoostClassifier(random_state=100, n_estimators=300)\n",
    "model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8594104308390023\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.94      0.92       371\n",
      "          1       0.57      0.44      0.50        70\n",
      "\n",
      "avg / total       0.85      0.86      0.85       441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_test = model.predict(test_x)\n",
    "print(accuracy_score(test_y, pred_test))\n",
    "print(classification_report(test_y, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_tree(model, columns):\n",
    "    import pydotplus\n",
    "    from sklearn.externals.six import StringIO\n",
    "    from IPython.display import Image\n",
    "    import os\n",
    "    from sklearn import tree\n",
    "    \n",
    "    graphviz_path = 'C:\\Program Files (x86)\\Graphviz2.38/bin/'\n",
    "    os.environ[\"PATH\"] += os.pathsep + graphviz_path\n",
    "\n",
    "    dot_data = StringIO()\n",
    "    tree.export_graphviz(model,\n",
    "                         out_file=dot_data,\n",
    "                         feature_names=columns)\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "    return Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16229349, 0.34244608, 0.36434203, 0.40214249, 0.40601838])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_tree(model.estimators_[250], train_x.columns)\n",
    "model.estimator_errors_[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity & Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44285714285714284 0.9380053908355795\n"
     ]
    }
   ],
   "source": [
    "pred_probs = pd.DataFrame(model.predict_proba(test_x),\n",
    "                          columns=['Neg', 'Pos'])\n",
    "pred_test = pred_probs['Pos'].apply(lambda v: 1 if v>0.5 else 0)\n",
    "#print(classification_report(test_y, pred_test))\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(test_y, pred_test).ravel()\n",
    "sensitivity = (tp)/ (tp+fn)\n",
    "specificity = tn / (tn+fp)\n",
    "print(sensitivity, specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "pred_test = pred_probs['Pos'].apply(lambda v: 1 if v>0.4 else 0)\n",
    "tn, fp, fn, tp = confusion_matrix(test_y, pred_test).ravel()\n",
    "sensitivity = (tp)/ (tp+fn)\n",
    "specificity = tn / (tn+fp)\n",
    "print(sensitivity, specificity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
